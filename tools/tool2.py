"""
Tool2: Regulation RAG Tool

ê·œì œ ì²´í¬ë¦¬ìŠ¤íŠ¸ ê²€ì¦ ë° ì •ê·œí™”ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ICH/MFDS ê°€ì´ë“œë¼ì¸ ê¸°ë°˜ ê²€ì¦
- ìš©ì–´ ìë™ ì •ê·œí™” (major violations)
- Hybrid ê²€ìƒ‰ (Vector + BM25 + MMR)
- ê·œì œ ê·¼ê±° citation ë°˜í™˜
- CTD_bundle.xlsx íŒŒì‹± ë° ì‹œíŠ¸ë³„ ê²€ì¦

Architecture:
    Input (CTD_bundle.xlsx) â†’ Parse sheets â†’ Validate â†’ Auto-normalize â†’ Return citations

ì‚¬ìš© ì˜ˆì‹œ:
    from tools.reg_rag import RegulationRAGTool

    # ë°©ë²• 1: ì—‘ì…€ íŒŒì¼ ì „ì²´ ê²€ì¦
    tool = RegulationRAGTool()
    results = tool.validate_excel("tool1/input/CTD_bundle.xlsx")

    # ë°©ë²• 2: íŠ¹ì • ì‹œíŠ¸/ì„¹ì…˜ë§Œ ê²€ì¦
    result = tool.validate_and_normalize(
        section="M2.7",
        content="ì„ìƒì‹œí—˜ ê°œìš”...",
        auto_fix=True
    )
"""

import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
import openpyxl

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from rag.mfds_rag import MFDSRAGTool
from rag.glossary_rag import GlossaryRAGTool
from rag.term_normalizer import TermNormalizer
# from rag.bm25_search import BM25Search  # TODO: í•„ìš”ì‹œ í™œì„±í™”


# CTD ì‹œíŠ¸ëª… â†’ ëª¨ë“ˆ ë§¤í•‘
SHEET_TO_MODULE = {
    "TM_5_M2_3_QOS": "M2.3",
    "TM_5_M2_4_Nonclinical_Ove": "M2.4",
    "TM_5_M2_5_Clinical_Overvi": "M2.5",
    "TM_5_M2_6_Nonclinical_Sum": "M2.6",
    "TM_5_M2_7_Clinical_Summar": "M2.7",
    "TM_5_Admin_Labeling_KR": "M1",
    "TM_5_Nonclinical": "M2.6",  # ë¹„ì„ìƒ ì›ë³¸ ë°ì´í„°
    "TM_5_Phase1": "M2.7",  # ì„ìƒ 1ìƒ ë°ì´í„°
    "TM_5_Phase2": "M2.7",  # ì„ìƒ 2ìƒ ë°ì´í„°
    "TM_5_Phase3": "M2.7",  # ì„ìƒ 3ìƒ ë°ì´í„°
}


class RegulationRAGTool:
    """
    Tool2: ê·œì œ ê²€ì¦ ë° ì •ê·œí™” ë„êµ¬

    Attributes:
        mfds_rag: MFDS/ICH ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰
        glossary_rag: ìš©ì–´ì§‘ ê²€ìƒ‰
        normalizer: ìš©ì–´ ì •ê·œí™” (Llama-3.2)
        bm25: BM25 ê²€ìƒ‰
    """

    def __init__(
        self,
        auto_normalize: bool = True,
        max_violations: int = 10,
        coverage_threshold: float = 0.7,
        enable_rag: bool = True
    ):
        """
        RegulationRAGTool ì´ˆê¸°í™”

        Args:
            auto_normalize: ìë™ ì •ê·œí™” í™œì„±í™” ì—¬ë¶€
            max_violations: ìµœëŒ€ í—ˆìš© ìœ„ë°˜ ê±´ìˆ˜
            coverage_threshold: ìµœì†Œ ì»¤ë²„ë¦¬ì§€ ë¹„ìœ¨ (0~1)
            enable_rag: RAG ë„êµ¬ ì´ˆê¸°í™” ì—¬ë¶€ (Falseë©´ ê²½ëŸ‰ ëª¨ë“œ)
        """
        print("ğŸ”§ RegulationRAGTool ì´ˆê¸°í™” ì¤‘...")

        self.auto_normalize = auto_normalize
        self.max_violations = max_violations
        self.coverage_threshold = coverage_threshold
        self.enable_rag = enable_rag

        # RAG ë„êµ¬ ì´ˆê¸°í™” (ì„ íƒì )
        if enable_rag:
            try:
                self.mfds_rag = MFDSRAGTool()
                self.glossary_rag = GlossaryRAGTool()
                print("âœ… RAG ë„êµ¬ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸  RAG ë„êµ¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                print("   â†’ ê²½ëŸ‰ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤ (RAG ë¹„í™œì„±í™”)")
                self.mfds_rag = None
                self.glossary_rag = None
                self.enable_rag = False
        else:
            self.mfds_rag = None
            self.glossary_rag = None

        # ìš©ì–´ ì •ê·œí™”ê¸° (ì„ íƒì )
        if auto_normalize:
            try:
                self.normalizer = TermNormalizer()
            except Exception as e:
                print(f"âš ï¸  TermNormalizer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.normalizer = None
        else:
            self.normalizer = None

        # BM25 ê²€ìƒ‰ê¸° (ì»¤ë²„ë¦¬ì§€ í™•ì¥ìš©)
        self.bm25 = None  # TODO: BM25Searcher ì´ˆê¸°í™”

        print("âœ… RegulationRAGTool ì´ˆê¸°í™” ì™„ë£Œ\n")

    def validate_excel(
        self,
        excel_path: str,
        auto_fix: bool = True
    ) -> Dict[str, Any]:
        """
        CTD_bundle.xlsx ì „ì²´ ê²€ì¦

        Args:
            excel_path: ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
            auto_fix: ìë™ ìˆ˜ì • í™œì„±í™” ì—¬ë¶€

        Returns:
            {
                "total_sheets": int,
                "validated_sheets": int,
                "results": List[Dict],  # ì‹œíŠ¸ë³„ ê²€ì¦ ê²°ê³¼
                "summary": {
                    "total_violations": int,
                    "avg_coverage": float,
                    "pass_rate": float
                }
            }
        """
        print(f"ğŸ“‚ CTD Bundle ê²€ì¦ ì‹œì‘: {excel_path}")
        print("=" * 70)

        wb = openpyxl.load_workbook(excel_path, data_only=True)
        results = []
        total_violations = 0
        total_coverage = 0.0

        for sheet_name in wb.sheetnames:
            # CTD ëª¨ë“ˆ ë§¤í•‘
            module = SHEET_TO_MODULE.get(sheet_name, "UNKNOWN")

            # ì‹œíŠ¸ ë‚´ìš© ì¶”ì¶œ
            ws = wb[sheet_name]
            content = self._extract_sheet_content(ws)

            print(f"\nğŸ” ì‹œíŠ¸ ê²€ì¦: {sheet_name} â†’ {module}")
            print(f"   ë‚´ìš© ê¸¸ì´: {len(content)} ì")

            # ê²€ì¦ ìˆ˜í–‰
            if len(content) < 10:
                print(f"   âš ï¸  ë‚´ìš©ì´ ë„ˆë¬´ ì§§ì•„ ê±´ë„ˆëœ€")
                continue

            result = self.validate_and_normalize(
                section=module,
                content=content,
                auto_fix=auto_fix
            )

            # ê²°ê³¼ ì €ì¥
            result['sheet_name'] = sheet_name
            result['module'] = module
            results.append(result)

            total_violations += len(result['violations'])
            total_coverage += result['coverage']

        # ìš”ì•½ í†µê³„
        validated_count = len(results)
        pass_count = sum(1 for r in results if r['pass'])

        summary = {
            "total_sheets": len(wb.sheetnames),
            "validated_sheets": validated_count,
            "results": results,
            "summary": {
                "total_violations": total_violations,
                "avg_coverage": total_coverage / validated_count if validated_count > 0 else 0.0,
                "pass_rate": pass_count / validated_count if validated_count > 0 else 0.0
            }
        }

        print("\n" + "=" * 70)
        print("ğŸ“Š ê²€ì¦ ì™„ë£Œ ìš”ì•½")
        print("=" * 70)
        print(f"   - ê²€ì¦ ì‹œíŠ¸: {validated_count}/{len(wb.sheetnames)}")
        print(f"   - Pass ë¹„ìœ¨: {summary['summary']['pass_rate']:.1%}")
        print(f"   - í‰ê·  ì»¤ë²„ë¦¬ì§€: {summary['summary']['avg_coverage']:.1%}")
        print(f"   - ì´ ìœ„ë°˜ì‚¬í•­: {total_violations}ê°œ")
        print("=" * 70 + "\n")

        return summary

    def _extract_sheet_content(self, ws) -> str:
        """
        ì—‘ì…€ ì‹œíŠ¸ì˜ í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ

        Args:
            ws: openpyxl worksheet

        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸
        """
        lines = []
        for row in ws.iter_rows(values_only=True):
            # Noneì´ ì•„ë‹Œ ì…€ë§Œ ì¶”ì¶œ
            cells = [str(cell).strip() for cell in row if cell is not None and str(cell).strip()]
            if cells:
                lines.append(" ".join(cells))

        return "\n".join(lines)

    def validate_and_normalize(
        self,
        section: str,
        content: str,
        auto_fix: bool = True
    ) -> Dict[str, Any]:
        """
        ê·œì œ ê²€ì¦ ë° ìë™ ì •ê·œí™”

        Args:
            section: CTD ì„¹ì…˜ (ì˜ˆ: "M2.7", "M2.6")
            content: ê²€ì¦í•  ë‚´ìš©
            auto_fix: ìë™ ìˆ˜ì • í™œì„±í™” ì—¬ë¶€

        Returns:
            {
                "validated": bool,
                "pass": bool,
                "violations": List[Dict],
                "normalized_content": str,
                "coverage": float,
                "citations": List[Dict],
                "rag_conf": float
            }
        """
        print(f"ğŸ” ê·œì œ ê²€ì¦ ì‹œì‘: {section}")

        # 1ë‹¨ê³„: ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ (RAG í™œì„±í™” ì‹œ)
        guideline_results = []
        if self.enable_rag and self.mfds_rag:
            try:
                guideline_results = self.mfds_rag.search_by_module(
                    query=content[:500],  # ì²« 500ìë¡œ ê²€ìƒ‰
                    module=section,
                    k=5
                )
            except Exception as e:
                print(f"âš ï¸  RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        else:
            print(f"   â†’ RAG ë¹„í™œì„±í™” ëª¨ë“œ (ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ ê±´ë„ˆëœ€)")

        # 2ë‹¨ê³„: ìœ„ë°˜ì‚¬í•­ íƒì§€
        violations = self._detect_violations(content, guideline_results)

        # 3ë‹¨ê³„: ìë™ ì •ê·œí™” (ì„ íƒì )
        normalized_content = content
        if auto_fix and violations and self.normalizer:
            print(f"âš ï¸  {len(violations)}ê°œ ìœ„ë°˜ì‚¬í•­ ë°œê²¬, ìë™ ì •ê·œí™” ì‹œë„...")
            normalized_content = self._normalize_content(content, violations)

        # 4ë‹¨ê³„: ì»¤ë²„ë¦¬ì§€ ê³„ì‚°
        coverage = self._calculate_coverage(normalized_content, guideline_results)

        # 5ë‹¨ê³„: ì»¤ë²„ë¦¬ì§€ í™•ì¥ (BM25 + MMR)
        if coverage < self.coverage_threshold:
            print(f"ğŸ“Š ì»¤ë²„ë¦¬ì§€ {coverage:.2%} < {self.coverage_threshold:.2%}, ì¶”ê°€ ê²€ìƒ‰...")
            expanded_results = self._expand_coverage(section, normalized_content)
            guideline_results.extend(expanded_results)
            coverage = self._calculate_coverage(normalized_content, guideline_results)

        # 6ë‹¨ê³„: Citation ìƒì„±
        citations = self._generate_citations(guideline_results)

        result = {
            "validated": True,
            "pass": len(violations) == 0,
            "violations": violations,
            "normalized_content": normalized_content,
            "coverage": coverage,
            "citations": citations,
            "rag_conf": self._calculate_confidence(guideline_results)
        }

        print(f"âœ… ê²€ì¦ ì™„ë£Œ: pass={result['pass']}, coverage={coverage:.2%}\n")
        return result

    def _detect_violations(
        self,
        content: str,
        guidelines: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        ìœ„ë°˜ì‚¬í•­ íƒì§€

        Args:
            content: ê²€ì¦í•  ë‚´ìš©
            guidelines: ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ ê²°ê³¼

        Returns:
            ìœ„ë°˜ì‚¬í•­ ë¦¬ìŠ¤íŠ¸ [{"type", "description", "suggestion"}]
        """
        violations = []

        # TODO: ì‹¤ì œ ê·œì¹™ ê¸°ë°˜ ê²€ì¦ ë¡œì§ êµ¬í˜„
        # ì˜ˆì‹œ:
        # - í•„ìˆ˜ ì„¹ì…˜ ëˆ„ë½ ì²´í¬
        # - ìš©ì–´ í‘œì¤€í™” ì²´í¬
        # - í¬ë§· ê·œì¹™ ì²´í¬

        return violations

    def _normalize_content(
        self,
        content: str,
        violations: List[Dict[str, Any]]
    ) -> str:
        """
        ìš©ì–´/í¬ë§· ìë™ ì •ê·œí™”

        Args:
            content: ì›ë³¸ ë‚´ìš©
            violations: ìœ„ë°˜ì‚¬í•­ ë¦¬ìŠ¤íŠ¸

        Returns:
            ì •ê·œí™”ëœ ë‚´ìš©
        """
        if not self.normalizer:
            return content

        # TODO: TermNormalizerë¥¼ ì‚¬ìš©í•œ ì •ê·œí™”
        normalized = self.normalizer.normalize(content)
        return normalized

    def _calculate_coverage(
        self,
        content: str,
        guidelines: List[Dict[str, Any]]
    ) -> float:
        """
        ê°€ì´ë“œë¼ì¸ ì»¤ë²„ë¦¬ì§€ ê³„ì‚°

        Args:
            content: ê²€ì¦ ëŒ€ìƒ ë‚´ìš©
            guidelines: ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ ê²°ê³¼

        Returns:
            ì»¤ë²„ë¦¬ì§€ ì ìˆ˜ (0~1)
        """
        # TODO: ì‹¤ì œ ì»¤ë²„ë¦¬ì§€ ê³„ì‚° ë¡œì§
        # ì˜ˆì‹œ: contentì˜ ì£¼ìš” í‚¤ì›Œë“œê°€ guidelinesì— ì–¼ë§ˆë‚˜ ë§¤ì¹­ë˜ëŠ”ì§€
        return 0.85

    def _expand_coverage(
        self,
        section: str,
        content: str
    ) -> List[Dict[str, Any]]:
        """
        BM25 + MMRë¡œ ì»¤ë²„ë¦¬ì§€ í™•ì¥

        Args:
            section: CTD ì„¹ì…˜
            content: ê²€ìƒ‰ ì¿¼ë¦¬

        Returns:
            ì¶”ê°€ ê²€ìƒ‰ ê²°ê³¼
        """
        # MMR ê²€ìƒ‰ìœ¼ë¡œ ë‹¤ì–‘ì„± í™•ë³´
        mmr_results = self.mfds_rag.search_with_mmr(
            query=content[:500],
            k=3,
            fetch_k=10,
            lambda_mult=0.5
        )

        return mmr_results

    def _generate_citations(
        self,
        guidelines: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Citation ë©”íƒ€ë°ì´í„° ìƒì„±

        Args:
            guidelines: ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ ê²°ê³¼

        Returns:
            Citation ë¦¬ìŠ¤íŠ¸ [{"source", "section", "page", "snippet"}]
        """
        citations = []
        for result in guidelines:
            citations.append({
                "source": result['metadata'].get('source', 'N/A'),
                "section": result['metadata'].get('module', 'N/A'),
                "page": result['metadata'].get('page', 'N/A'),
                "snippet": result['content'][:200] + "...",
                "score": result.get('score', 0.0)
            })
        return citations

    def _calculate_confidence(
        self,
        results: List[Dict[str, Any]]
    ) -> float:
        """
        RAG ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°

        Args:
            results: ê²€ìƒ‰ ê²°ê³¼

        Returns:
            ì‹ ë¢°ë„ ì ìˆ˜ (0~1)
        """
        if not results:
            return 0.0

        # ìƒìœ„ ê²°ê³¼ë“¤ì˜ í‰ê·  ìœ ì‚¬ë„
        scores = [r.get('score', 0.0) for r in results[:3]]
        return sum(scores) / len(scores) if scores else 0.0


# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    print("=" * 70)
    print("  Tool2: Regulation RAG Tool í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    print()

    # ë„êµ¬ ì´ˆê¸°í™” (ê²½ëŸ‰ ëª¨ë“œ: RAG ë¹„í™œì„±í™”)
    tool = RegulationRAGTool(
        auto_normalize=False,
        enable_rag=False  # í…ŒìŠ¤íŠ¸ì—ì„œëŠ” RAG ë¹„í™œì„±í™”
    )

    # ========== í…ŒìŠ¤íŠ¸ 1: CTD_bundle.xlsx ì „ì²´ ê²€ì¦ ==========
    print("\n" + "=" * 70)
    print("  í…ŒìŠ¤íŠ¸ 1: CTD_bundle.xlsx ì „ì²´ ê²€ì¦")
    print("=" * 70)

    excel_path = "../tool1/input/CTD_bundle.xlsx"
    if Path(excel_path).exists():
        summary = tool.validate_excel(excel_path, auto_fix=False)

        print("\nğŸ“Š ì‹œíŠ¸ë³„ ê²€ì¦ ê²°ê³¼:")
        for i, result in enumerate(summary['results'][:5], 1):  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
            print(f"\n{i}. [{result['sheet_name']}] â†’ {result['module']}")
            print(f"   - Pass: {result['pass']}")
            print(f"   - Coverage: {result['coverage']:.2%}")
            print(f"   - Violations: {len(result['violations'])}ê°œ")
            if result['citations']:
                print(f"   - Citations: {len(result['citations'])}ê°œ")
    else:
        print(f"âš ï¸  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {excel_path}")

    # ========== í…ŒìŠ¤íŠ¸ 2: ê°œë³„ ì‹œíŠ¸ ê²€ì¦ ==========
    print("\n" + "=" * 70)
    print("  í…ŒìŠ¤íŠ¸ 2: ê°œë³„ ë‚´ìš© ê²€ì¦")
    print("=" * 70)

    test_content = """
    meta:
      document: CTD M2.7 ì„ìƒ ìš”ì•½ â€“ TM-5(ê°€ìƒ)
      language: ko
      version: '1.0'

    ì„ìƒì‹œí—˜ ê°œìš”

    ë³¸ ì„ìƒì‹œí—˜ì€ Phase 2/3 ë‹¤ê¸°ê´€ ë¬´ì‘ìœ„ë°°ì • ì´ì¤‘ë§¹ê²€ ìœ„ì•½ëŒ€ì¡° ì—°êµ¬ë¡œ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.
    ì´ 500ëª…ì˜ í™˜ìê°€ ë“±ë¡ë˜ì—ˆìœ¼ë©°, ì‹œí—˜ì•½êµ°ê³¼ ìœ„ì•½êµ°ì— 1:1ë¡œ ë¬´ì‘ìœ„ ë°°ì •ë˜ì—ˆìŠµë‹ˆë‹¤.

    ì£¼ìš” íš¨ëŠ¥ í‰ê°€ë³€ìˆ˜ëŠ” 12ì£¼ì°¨ì˜ ì¦ìƒ ê°œì„ ìœ¨ì´ì—ˆìœ¼ë©°, ì‹œí—˜ì•½êµ°ì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ
    ê°œì„ ì„ ë³´ì˜€ìŠµë‹ˆë‹¤ (p<0.001).
    """

    result = tool.validate_and_normalize(
        section="M2.7",
        content=test_content,
        auto_fix=False
    )

    print("\nğŸ“‹ ê²€ì¦ ê²°ê³¼:")
    print(f"   - Pass: {result['pass']}")
    print(f"   - Coverage: {result['coverage']:.2%}")
    print(f"   - RAG Confidence: {result['rag_conf']:.2%}")
    print(f"   - Violations: {len(result['violations'])}ê°œ")
    print(f"   - Citations: {len(result['citations'])}ê°œ")

    print("\n" + "=" * 70)
    print("  í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 70)
