"""
Glossary RAG Tool

Qdrant Vector DBì— ì¸ë±ì‹±ëœ ìš©ì–´ì§‘ì„ ê²€ìƒ‰í•˜ëŠ” RAG ë„êµ¬ì…ë‹ˆë‹¤.
- ì˜ë£Œ/ì œì•½ ìš©ì–´ ì •ì˜ ê²€ìƒ‰
- ì¹´í…Œê³ ë¦¬ë³„ í•„í„°ë§
- ìœ ì‚¬ ìš©ì–´ ê²€ìƒ‰
- JSON ì›ë³¸ ë°ì´í„° íŒŒì‹±

ì‚¬ìš© ì˜ˆì‹œ:
    from tools.glossary_rag import GlossaryRAGTool

    rag = GlossaryRAGTool()
    results = rag.search_term("CTD ë¬¸ì„œë€?", k=5)

    # JSON íŒŒì‹±
    term_data = rag.parse_json_content(results[0]['content'])
    print(term_data['description_ko'])
"""

import sys
import json
from pathlib import Path
from typing import List, Optional, Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from langchain_qdrant import QdrantVectorStore
from langchain_core.documents import Document
from langchain_core.embeddings import Embeddings
from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue
from rag.embedding import E5Embedder


class E5EmbeddingAdapter(Embeddings):
    """
    LangChainì˜ Embeddings ì¸í„°í˜ì´ìŠ¤ì— ë§ì¶° E5Embedderë¥¼ ë˜í•‘í•˜ëŠ” ì–´ëŒ‘í„°
    """
    def __init__(self, embedder: E5Embedder):
        super().__init__()
        self.embedder = embedder
        self.task_description = "ì£¼ì–´ì§„ ì˜í•™ ë° ì œì•½ ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•´, ìš©ì–´ì§‘ì—ì„œ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì„¤ëª…ì„ ê²€ìƒ‰í•˜ì‹œì˜¤"

    def embed_documents(self, texts: list[str]) -> list[list[float]]:
        """ë¬¸ì„œ ì„ë² ë”© (ë°°ì¹˜ ì²˜ë¦¬)"""
        embeddings = self.embedder.embed_documents(texts, batch_size=32, show_progress_bar=False)
        return embeddings.cpu().numpy().tolist()

    def embed_query(self, text: str) -> list[float]:
        """ì¿¼ë¦¬ ì„ë² ë”© (instruction í¬í•¨)"""
        embeddings = self.embedder.embed_queries([text], task=self.task_description, batch_size=1)
        return embeddings.cpu().numpy().tolist()[0]

    async def aembed_documents(self, texts: list[str]) -> list[list[float]]:
        """ë¹„ë™ê¸° ë¬¸ì„œ ì„ë² ë”© (ë™ê¸° ë©”ì„œë“œ í˜¸ì¶œ)"""
        return self.embed_documents(texts)

    async def aembed_query(self, text: str) -> list[float]:
        """ë¹„ë™ê¸° ì¿¼ë¦¬ ì„ë² ë”© (ë™ê¸° ë©”ì„œë“œ í˜¸ì¶œ)"""
        return self.embed_query(text)


class GlossaryRAGTool:
    """
    Qdrant ê¸°ë°˜ ìš©ì–´ì§‘ ê²€ìƒ‰ ë„êµ¬

    Attributes:
        vector_store: QdrantVectorStore ì¸ìŠ¤í„´ìŠ¤
        client: Qdrant í´ë¼ì´ì–¸íŠ¸
        collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
    """

    def __init__(
        self,
        storage_path: Optional[str] = None,
        collection_name: str = "glossary_terms",
        model_name: str = "intfloat/multilingual-e5-large-instruct"
    ):
        """
        GlossaryRAGTool ì´ˆê¸°í™”

        Args:
            storage_path: Qdrant ì €ì¥ ê²½ë¡œ (ê¸°ë³¸: ./qdrant_storage/glossary)
            collection_name: ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ ì´ë¦„
            model_name: ì„ë² ë”© ëª¨ë¸ ì´ë¦„
        """
        if storage_path is None:
            storage_path = str(project_root / "qdrant_storage" / "glossary")

        self.storage_path = storage_path
        self.collection_name = collection_name

        # Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = QdrantClient(path=storage_path)

        # E5 ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        print(f"ğŸ¤– E5 ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘... ({model_name})")
        embedder = E5Embedder(model_name=model_name)
        self.embedding_adapter = E5EmbeddingAdapter(embedder)

        # Vector Store ì´ˆê¸°í™”
        self.vector_store = QdrantVectorStore(
            client=self.client,
            collection_name=collection_name,
            embedding=self.embedding_adapter
        )

        print(f"âœ… GlossaryRAGTool ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   - Storage: {storage_path}")
        print(f"   - Collection: {collection_name}\n")

    def search_term(
        self,
        query: str,
        k: int = 5,
        score_threshold: Optional[float] = None
    ) -> List[Dict[str, Any]]:
        """
        ìš©ì–´ ê²€ìƒ‰ (ìœ ì‚¬ë„ ê¸°ë°˜)

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            score_threshold: ìµœì†Œ ìœ ì‚¬ë„ ì ìˆ˜ (0~1)

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ [{"term", "content", "category", "score", "metadata"}]
        """
        print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: '{query}' (top-{k})")

        if score_threshold:
            results = self.vector_store.similarity_search_with_score(
                query=query,
                k=k,
            )
            # ì ìˆ˜ í•„í„°ë§
            results = [(doc, score) for doc, score in results if score >= score_threshold]
        else:
            results = self.vector_store.similarity_search_with_score(
                query=query,
                k=k
            )

        # ê²°ê³¼ í¬ë§·íŒ…
        formatted_results = []
        for doc, score in results:
            formatted_results.append({
                "term": doc.metadata.get("term", "N/A"),
                "term_en": doc.metadata.get("term_en", "N/A"),
                "category": doc.metadata.get("category", "N/A"),
                "content": doc.page_content,
                "score": float(score),
                "synonyms": doc.metadata.get("synonyms", []),
                "metadata": doc.metadata
            })

        print(f"ğŸ“Š ê²€ìƒ‰ ì™„ë£Œ: {len(formatted_results)}ê°œ ê²°ê³¼ ë°˜í™˜\n")
        return formatted_results

    def search_by_category(
        self,
        query: str,
        category: str,
        k: int = 3
    ) -> List[Dict[str, Any]]:
        """
        ì¹´í…Œê³ ë¦¬ë³„ í•„í„°ë§ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            category: í•„í„°ë§í•  ì¹´í…Œê³ ë¦¬ (ì˜ˆ: "R&D", "ì„ìƒ_ë¹„ì„ìƒ")
            k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        print(f"ğŸ” ì¹´í…Œê³ ë¦¬ í•„í„°ë§ ê²€ìƒ‰: '{query}' [ì¹´í…Œê³ ë¦¬: {category}]")

        # Qdrant í•„í„° ìƒì„± (ì¤‘ì²© êµ¬ì¡° ì ‘ê·¼)
        filter_condition = Filter(
            must=[
                FieldCondition(
                    key="metadata.category",
                    match=MatchValue(value=category)
                )
            ]
        )

        # ê²€ìƒ‰ ì‹¤í–‰
        results = self.vector_store.similarity_search_with_score(
            query=query,
            k=k,
            filter=filter_condition
        )

        # ê²°ê³¼ í¬ë§·íŒ…
        formatted_results = []
        for doc, score in results:
            formatted_results.append({
                "term": doc.metadata.get("term", "N/A"),
                "term_en": doc.metadata.get("term_en", "N/A"),
                "category": doc.metadata.get("category", "N/A"),
                "content": doc.page_content,
                "score": float(score),
                "synonyms": doc.metadata.get("synonyms", []),
                "metadata": doc.metadata
            })

        print(f"ğŸ“Š ê²€ìƒ‰ ì™„ë£Œ: {len(formatted_results)}ê°œ ê²°ê³¼ ë°˜í™˜\n")
        return formatted_results

    def search_with_mmr(
        self,
        query: str,
        k: int = 5,
        fetch_k: int = 20,
        lambda_mult: float = 0.5
    ) -> List[Dict[str, Any]]:
        """
        MMR (Maximal Marginal Relevance) ê¸°ë°˜ ë‹¤ì–‘ì„± ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ìµœì¢… ë°˜í™˜ ê²°ê³¼ ìˆ˜
            fetch_k: ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
            lambda_mult: ê´€ë ¨ì„± vs ë‹¤ì–‘ì„± ê°€ì¤‘ì¹˜ (0~1, ë†’ì„ìˆ˜ë¡ ê´€ë ¨ì„± ìš°ì„ )

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        print(f"ğŸ” MMR ê²€ìƒ‰: '{query}' (k={k}, fetch_k={fetch_k}, Î»={lambda_mult})")

        results = self.vector_store.max_marginal_relevance_search(
            query=query,
            k=k,
            fetch_k=fetch_k,
            lambda_mult=lambda_mult
        )

        # ê²°ê³¼ í¬ë§·íŒ…
        formatted_results = []
        for doc in results:
            formatted_results.append({
                "term": doc.metadata.get("term", "N/A"),
                "term_en": doc.metadata.get("term_en", "N/A"),
                "category": doc.metadata.get("category", "N/A"),
                "content": doc.page_content,
                "synonyms": doc.metadata.get("synonyms", []),
                "metadata": doc.metadata
            })

        print(f"ğŸ“Š MMR ê²€ìƒ‰ ì™„ë£Œ: {len(formatted_results)}ê°œ ê²°ê³¼ ë°˜í™˜\n")
        return formatted_results

    def get_term_by_exact_match(self, term: str) -> Optional[Dict[str, Any]]:
        """
        ì •í™•í•œ ìš©ì–´ ë§¤ì¹­ìœ¼ë¡œ ê²€ìƒ‰

        Args:
            term: ê²€ìƒ‰í•  ìš©ì–´ (ì˜ˆ: "CTD", "ADME")

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ (ì—†ìœ¼ë©´ None)
        """
        print(f"ğŸ¯ ì •í™•í•œ ìš©ì–´ ê²€ìƒ‰: '{term}'")

        filter_condition = Filter(
            must=[
                FieldCondition(
                    key="metadata.term",  # ì¤‘ì²©ëœ êµ¬ì¡° ì ‘ê·¼
                    match=MatchValue(value=term)
                )
            ]
        )

        results = self.vector_store.similarity_search(
            query=term,
            k=1,
            filter=filter_condition
        )

        if results:
            doc = results[0]
            return {
                "term": doc.metadata.get("term", "N/A"),
                "term_en": doc.metadata.get("term_en", "N/A"),
                "category": doc.metadata.get("category", "N/A"),
                "content": doc.page_content,
                "synonyms": doc.metadata.get("synonyms", []),
                "metadata": doc.metadata
            }

        print(f"âŒ ìš©ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: '{term}'\n")
        return None

    @staticmethod
    def parse_json_content(content: str) -> Dict[str, Any]:
        """
        ê²€ìƒ‰ ê²°ê³¼ì˜ content(JSON ë¬¸ìì—´)ë¥¼ íŒŒì‹±í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜

        Args:
            content: JSON ë¬¸ìì—´ (ê²€ìƒ‰ ê²°ê³¼ì˜ 'content' í•„ë“œ)

        Returns:
            íŒŒì‹±ëœ ìš©ì–´ ë°ì´í„° ë”•ì…”ë„ˆë¦¬

        Example:
            >>> result = rag.search_term("CTD")[0]
            >>> data = rag.parse_json_content(result['content'])
            >>> print(data['description_ko'])
            'ì˜ì•½í’ˆ í’ˆëª©í—ˆê°€ ì‹ ì²­ ì‹œ ìë£Œ êµ¬ì„±ì„ í‘œì¤€í™”í•œ êµ­ì œ ê³µí†µ ì–‘ì‹.'
        """
        try:
            return json.loads(content)
        except json.JSONDecodeError as e:
            print(f"âš ï¸  JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return {}

    def get_description(self, term: str) -> Optional[str]:
        """
        íŠ¹ì • ìš©ì–´ì˜ ì„¤ëª…ë§Œ ê°„ë‹¨íˆ ë°˜í™˜

        Args:
            term: ê²€ìƒ‰í•  ìš©ì–´

        Returns:
            ìš©ì–´ ì„¤ëª… (ì—†ìœ¼ë©´ None)

        Example:
            >>> rag.get_description("CTD")
            'ì˜ì•½í’ˆ í’ˆëª©í—ˆê°€ ì‹ ì²­ ì‹œ ìë£Œ êµ¬ì„±ì„ í‘œì¤€í™”í•œ êµ­ì œ ê³µí†µ ì–‘ì‹.'
        """
        result = self.get_term_by_exact_match(term)
        if result:
            data = self.parse_json_content(result['content'])
            return data.get('description_ko')
        return None


# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    print("=" * 70)
    print("  Glossary RAG Tool í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    print()

    # ë„êµ¬ ì´ˆê¸°í™”
    rag = GlossaryRAGTool()

    # í…ŒìŠ¤íŠ¸ 1: ì¼ë°˜ ê²€ìƒ‰
    print("\n" + "=" * 70)
    print("  í…ŒìŠ¤íŠ¸ 1: ì¼ë°˜ ê²€ìƒ‰")
    print("=" * 70 + "\n")

    results = rag.search_term("CTD ë¬¸ì„œë€ ë¬´ì—‡ì¸ê°€?", k=3)
    for i, result in enumerate(results, 1):
        print(f"{i}. [{result['term']}] (ìœ ì‚¬ë„: {result['score']:.4f})")
        print(f"   ì¹´í…Œê³ ë¦¬: {result['category']}")
        print(f"   {result['content'][:100]}...")
        print()

    # í…ŒìŠ¤íŠ¸ 2: ì¹´í…Œê³ ë¦¬ í•„í„°ë§
    print("\n" + "=" * 70)
    print("  í…ŒìŠ¤íŠ¸ 2: ì¹´í…Œê³ ë¦¬ í•„í„°ë§ ê²€ìƒ‰")
    print("=" * 70 + "\n")

    results = rag.search_by_category("ì„ìƒì‹œí—˜", category="R&D", k=3)
    for i, result in enumerate(results, 1):
        print(f"{i}. [{result['term']}] (ìœ ì‚¬ë„: {result['score']:.4f})")
        print(f"   {result['content'][:100]}...")
        print()

    # í…ŒìŠ¤íŠ¸ 3: ì •í™•í•œ ë§¤ì¹­
    print("\n" + "=" * 70)
    print("  í…ŒìŠ¤íŠ¸ 3: ì •í™•í•œ ìš©ì–´ ë§¤ì¹­")
    print("=" * 70 + "\n")

    result = rag.get_term_by_exact_match("ADME")
    if result:
        print(f"âœ… ìš©ì–´ ë°œê²¬: {result['term']} ({result['term_en']})")
        print(f"   JSON ì›ë³¸: {result['content'][:100]}...")

        # JSON íŒŒì‹± í…ŒìŠ¤íŠ¸
        data = rag.parse_json_content(result['content'])
        print(f"\n   íŒŒì‹±ëœ ë°ì´í„°:")
        print(f"   - ì¹´í…Œê³ ë¦¬: {data.get('category')}")
        print(f"   - ìš©ì–´: {data.get('term')}")
        print(f"   - ì„¤ëª…: {data.get('description_ko')}")
        print(f"   - ë™ì˜ì–´: {data.get('synonyms')}")
    else:
        print("âŒ ìš©ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # í…ŒìŠ¤íŠ¸ 4: get_description í—¬í¼ ë©”ì„œë“œ
    print("\n" + "=" * 70)
    print("  í…ŒìŠ¤íŠ¸ 4: ìš©ì–´ ì„¤ëª… ê°„ë‹¨ ì¡°íšŒ")
    print("=" * 70 + "\n")

    description = rag.get_description("CTD")
    if description:
        print(f"âœ… CTD ì„¤ëª…: {description}")
    else:
        print("âŒ ìš©ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    print("\n" + "=" * 70)
    print("  í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 70)
