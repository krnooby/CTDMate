"""
BM25 Search Module

MFDS/ICH ê°€ì´ë“œë¼ì¸ ë¬¸ì„œì— ëŒ€í•œ BM25 í‚¤ì›Œë“œ ê²€ìƒ‰
- rank_bm25 ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
- í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ (ê°„ë‹¨í•œ ê³µë°± ê¸°ë°˜ í† í¬ë‚˜ì´ì§•)
- JSONL ë°ì´í„° ì¸ë±ì‹±
- Vector ê²€ìƒ‰ê³¼ í•˜ì´ë¸Œë¦¬ë“œ ì‚¬ìš©

ì‚¬ìš© ì˜ˆì‹œ:
    from tools.bm25_search import BM25Search

    bm25 = BM25Search()
    results = bm25.search("ì„ìƒ ìš”ì•½ ì‘ì„±", k=5)
"""

import sys
import json
import pickle
from pathlib import Path
from typing import List, Dict, Any, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from rank_bm25 import BM25Okapi


class BM25Search:
    """
    BM25 ê¸°ë°˜ í‚¤ì›Œë“œ ê²€ìƒ‰ ë„êµ¬

    Attributes:
        corpus: ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        bm25: BM25Okapi ì¸ìŠ¤í„´ìŠ¤
        documents: ì›ë³¸ ë¬¸ì„œ ë©”íƒ€ë°ì´í„°
    """

    def __init__(
        self,
        data_path: Optional[str] = None,
        index_path: Optional[str] = None
    ):
        """
        BM25Search ì´ˆê¸°í™”

        Args:
            data_path: MFDS JSONL ë°ì´í„° ê²½ë¡œ (ê¸°ë³¸: data/MFDS/MFDS_final.jsonl)
            index_path: BM25 ì¸ë±ìŠ¤ ì €ì¥ ê²½ë¡œ (ê¸°ë³¸: qdrant_storage/mfds_bm25.pkl)
        """
        if data_path is None:
            data_path = str(project_root / "data" / "MFDS" / "MFDS_final.jsonl")

        if index_path is None:
            index_path = str(project_root / "qdrant_storage" / "mfds_bm25.pkl")

        self.data_path = data_path
        self.index_path = index_path
        self.corpus: List[List[str]] = []
        self.documents: List[Dict[str, Any]] = []
        self.bm25: Optional[BM25Okapi] = None

        # ì¸ë±ìŠ¤ ë¡œë“œ ë˜ëŠ” êµ¬ì¶•
        if Path(index_path).exists():
            print(f"ğŸ“‚ BM25 ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘... ({index_path})")
            self._load_index()
        else:
            print(f"ğŸ”¨ BM25 ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘... ({data_path})")
            self._build_index()
            self._save_index()

        print(f"âœ… BM25Search ì´ˆê¸°í™” ì™„ë£Œ (ë¬¸ì„œ ìˆ˜: {len(self.documents)})\n")

    def _build_index(self):
        """MFDS JSONL ë°ì´í„°ë¡œë¶€í„° BM25 ì¸ë±ìŠ¤ êµ¬ì¶•"""
        # JSONL ì½ê¸°
        with open(self.data_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:  # ë¹ˆ ì¤„ ê±´ë„ˆë›°ê¸°
                    continue
                doc = json.loads(line)
                self.documents.append(doc)

                # ê²€ìƒ‰ ëŒ€ìƒ í…ìŠ¤íŠ¸ ìƒì„± (ì œëª© + ì„¤ëª… + ì²´í¬ë¦¬ìŠ¤íŠ¸)
                search_text = self._create_search_text(doc)
                tokens = self._tokenize(search_text)
                self.corpus.append(tokens)

        # BM25 ì¸ë±ìŠ¤ êµ¬ì¶•
        self.bm25 = BM25Okapi(self.corpus)
        print(f"ğŸ“Š BM25 ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {len(self.documents)}ê°œ ë¬¸ì„œ")

    def _create_search_text(self, doc: Dict[str, Any]) -> str:
        """
        ë¬¸ì„œì—ì„œ ê²€ìƒ‰ ëŒ€ìƒ í…ìŠ¤íŠ¸ ìƒì„±

        Args:
            doc: MFDS ë¬¸ì„œ ë”•ì…”ë„ˆë¦¬

        Returns:
            í†µí•© ê²€ìƒ‰ í…ìŠ¤íŠ¸
        """
        parts = [
            doc.get("title", ""),
            doc.get("description", ""),
            " ".join(doc.get("checklist", []))
        ]
        return " ".join(parts)

    def _tokenize(self, text: str) -> List[str]:
        """
        ê°„ë‹¨í•œ í† í¬ë‚˜ì´ì§• (ê³µë°± ê¸°ë°˜)

        ì¶”í›„ KoNLPy ë“±ìœ¼ë¡œ ê°œì„  ê°€ëŠ¥

        Args:
            text: ì…ë ¥ í…ìŠ¤íŠ¸

        Returns:
            í† í° ë¦¬ìŠ¤íŠ¸
        """
        # ê°„ë‹¨í•œ ê³µë°± ë¶„ë¦¬ + íŠ¹ìˆ˜ë¬¸ì ì œê±°
        tokens = text.lower().split()
        return [t.strip(".,!?()[]{}:;") for t in tokens if len(t) > 1]

    def _save_index(self):
        """BM25 ì¸ë±ìŠ¤ ì €ì¥ (pickle)"""
        index_dir = Path(self.index_path).parent
        index_dir.mkdir(parents=True, exist_ok=True)

        with open(self.index_path, 'wb') as f:
            pickle.dump({
                'corpus': self.corpus,
                'documents': self.documents,
                'bm25': self.bm25
            }, f)

        print(f"ğŸ’¾ BM25 ì¸ë±ìŠ¤ ì €ì¥: {self.index_path}")

    def _load_index(self):
        """BM25 ì¸ë±ìŠ¤ ë¡œë“œ (pickle)"""
        with open(self.index_path, 'rb') as f:
            data = pickle.load(f)
            self.corpus = data['corpus']
            self.documents = data['documents']
            self.bm25 = data['bm25']

        print(f"âœ… BM25 ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {len(self.documents)}ê°œ ë¬¸ì„œ")

    def search(
        self,
        query: str,
        k: int = 5,
        score_threshold: float = 0.0
    ) -> List[Dict[str, Any]]:
        """
        BM25 ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            score_threshold: ìµœì†Œ BM25 ì ìˆ˜ (ê¸°ë³¸: 0.0, í•„í„°ë§ ì•ˆí•¨)

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ [{"module", "section", "title", "score", ...}]

        Example:
            >>> bm25 = BM25Search()
            >>> results = bm25.search("ì„ìƒ ìš”ì•½", k=3)
            >>> for r in results:
            ...     print(f"{r['section']}: {r['title']} (ì ìˆ˜: {r['score']:.2f})")
        """
        print(f"ğŸ” BM25 ê²€ìƒ‰: '{query}' (top-{k})")

        # ì¿¼ë¦¬ í† í¬ë‚˜ì´ì§•
        query_tokens = self._tokenize(query)

        # BM25 ì ìˆ˜ ê³„ì‚°
        scores = self.bm25.get_scores(query_tokens)

        # ìƒìœ„ kê°œ ì¸ë±ìŠ¤ ë° ì ìˆ˜ ì¶”ì¶œ
        top_indices = sorted(
            range(len(scores)),
            key=lambda i: scores[i],
            reverse=True
        )[:k]

        # ê²°ê³¼ í¬ë§·íŒ…
        results = []
        for idx in top_indices:
            score = float(scores[idx])

            # ì ìˆ˜ í•„í„°ë§
            if score < score_threshold:
                continue

            doc = self.documents[idx]
            results.append({
                "module": doc.get("module", "N/A"),
                "section": doc.get("section", "N/A"),
                "title": doc.get("title", "N/A"),
                "description": doc.get("description", "N/A"),
                "checklist": doc.get("checklist", []),
                "cross_ref": doc.get("cross_ref", []),
                "score": score,
                "metadata": doc
            })

        print(f"ğŸ“Š BM25 ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼\n")
        return results

    def rebuild_index(self):
        """ì¸ë±ìŠ¤ ì¬êµ¬ì¶•"""
        print("ğŸ”„ BM25 ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì¤‘...")
        self.corpus = []
        self.documents = []
        self._build_index()
        self._save_index()


# ========== ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸ ==========
if __name__ == "__main__":
    print("=" * 70)
    print("  BM25Search í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    print()

    # BM25Search ì´ˆê¸°í™”
    bm25 = BM25Search()

    # í…ŒìŠ¤íŠ¸ 1: ê¸°ë³¸ ê²€ìƒ‰
    print("\n[í…ŒìŠ¤íŠ¸ 1] ê¸°ë³¸ BM25 ê²€ìƒ‰")
    print("-" * 70)
    results = bm25.search("ì„ìƒ ìš”ì•½ ì‘ì„± ë°©ë²•", k=5)

    for i, r in enumerate(results, 1):
        print(f"{i}. [{r['section']}] {r['title']}")
        print(f"   BM25 ì ìˆ˜: {r['score']:.4f}")
        print(f"   ì„¤ëª…: {r['description'][:60]}...")
        print()

    # í…ŒìŠ¤íŠ¸ 2: íŠ¹ì • í‚¤ì›Œë“œ ê²€ìƒ‰
    print("\n[í…ŒìŠ¤íŠ¸ 2] íŠ¹ì • í‚¤ì›Œë“œ ê²€ìƒ‰")
    print("-" * 70)
    results2 = bm25.search("ì•½ë™í•™ PK ADME", k=3)

    for i, r in enumerate(results2, 1):
        print(f"{i}. [{r['section']}] {r['title']} (ì ìˆ˜: {r['score']:.2f})")

    # í…ŒìŠ¤íŠ¸ 3: ì ìˆ˜ ì„ê³„ê°’ ì ìš©
    print("\n[í…ŒìŠ¤íŠ¸ 3] ì ìˆ˜ ì„ê³„ê°’ í•„í„°ë§ (threshold=5.0)")
    print("-" * 70)
    results3 = bm25.search("ì„ìƒì‹œí—˜", k=10, score_threshold=5.0)

    print(f"ì„ê³„ê°’ ì´ìƒ ê²°ê³¼: {len(results3)}ê°œ")
    for i, r in enumerate(results3[:5], 1):
        print(f"{i}. [{r['section']}] {r['title']} (ì ìˆ˜: {r['score']:.2f})")

    print("\n" + "=" * 70)
    print("  í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 70)
